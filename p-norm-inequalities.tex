\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\input{liatex/preamble}

\title{$p$-norm inequalities}
\author{Lily Chung}
\date{}

\begin{document}
\maketitle

Let $f : S \to [0, \infty]$ be a measurable function on a nonzero measure space $(S, \Lambda, \mu)$.
Define \[\norm{f}_p \eqdef \begin{cases}
  \left(\int f^p\,d\mu\right)^{1/p} & p \in \R - \{0\} \\
  \esssup f & p = \infty \\
  \essinf f & p = -\infty \\
  \lim_{r \to p} \norm{f}_r & p \in \{0^-, 0, 0^+\} \\
  \end{cases}
\]
where $x \mapsto x^{-1}$ is extended continuously to zero and infinite values.
Be aware that this does not define a seminorm unless $p \ge 1$.
Also note that $\norm{f}_0$ may not exist, but $\norm{f}_p$ exists for every other $p$.

It's useful to observe the symmetry $\norm{f}_{-p} = \norm{f^{-1}}_p^{-1}$.

\section*{Power Mean Inequality}

The following monotonicity result holds for probability spaces:

\begin{theorem}[Power Mean Inequality]\label{thm:power mean}
  Suppose $\mu(S) = 1$ and let $X : S \to [0, \infty]$ be a random variable.
  If $p \le q$ then $\norm{X}_p \le \norm{X}_q$.
\end{theorem}
\begin{proof}
  Suppose $p < q$ with $p, q \in \R - \{0\}$.
  Applying Jensen's inequality to the map $u \mapsto u^{q/p}$,
  which is convex if $q > 0$ and concave if $q < 0$,
  yields the inequality.
  The $0^-, 0^+$ cases follow from these,
  and the cases where $p$ or $q$ are infinite are trivial.
\end{proof}

For instance this generalizes the AM-GM inequality since $\norm{\cdot}_0$ is the geometric mean and $\norm{\cdot}_1$ is the arithmetic mean.

\section*{Limits}

\begin{theorem}\label{thm:limit infinity}
  Let $f : S \to [0, \infty]$ be a measurable function.
  Then \[
  \lim_{p \to \infty} \norm{f}_p = \norm{f}_\infty
  \]
  provided $\norm{f}_q < \infty$ for some $q \in (0, \infty)$,
  and similarly
  \[
  \lim_{p \to -\infty} \norm{f}_p = \norm{f}_{-\infty}
  \]
  provided $\norm{f}_q > 0$ for some $q \in (-\infty, 0)$.
\end{theorem}
\begin{proof}
  By symmetry we only need to prove the first statement.
  In one direction, suppose $\mu[f > c] > 0$.
  Then we have
  \[
  \norm{f}_p &\ge \left(\int_{f > c} f^p\,d\mu\right)^{1/p} \ge c \mu[f > c]^{1/p} \\
  \]
  which is either equal to $\infty$ or approaches $c$ as $p \to \infty$;
  either way we find $\liminf_{p \to \infty} \norm{f}_p \ge \norm{f}_\infty$.

  In the other direction, for $p > q$ write
  \[
  \norm{f}_p &= \left(\int f^{p - q}f^q\,d\mu\right)^{1/p} \\
  &\le \left(\int \norm{f}_\infty^{p - q} f^q\,d\mu\right)^{1/p} \\
  &= \norm{f}_\infty^{1 - \frac{q}{p}} \norm{f}_q^{q/p} \\
  & \to \norm{f}_\infty \\
  \]
  which completes the proof.
\end{proof}

\begin{theorem}\label{thm:limit positive}
  Let $f : S \to [0, \infty]$ be a measurable function
  such that $\norm{f}_q < \infty$ for some $q \in (0, \infty)$.
  Then $p \mapsto \norm{f}_p$ is continuous on $(0, q]$.
  Similarly if $\norm{f}_q > 0$ for some $q \in (-\infty, 0)$ then $p \mapsto \norm{f}_p$ is continuous on $[q, 0)$.
\end{theorem}
\begin{proof}
  By symmetry we only need to prove the first statement;
  the provision implies $f < \infty$ almost everywhere.
  We can observe that $x \mapsto x^p$ is increasing for $x \ge 1$
  and decreasing for $x \le 1$.
  Thus we can decompose $f^p = f^p[f \le 1] + f^p[f > 1]$
  and apply monotone convergence separately for each part;
  the decreasing part requires the hypothesis $\norm{f}_q < \infty$.
\end{proof}

\begin{theorem}\label{thm:limit zero}
  Let $f : S \to [0, \infty]$ be a measurable function. 
  Then
  \[
  \norm{f}_{0^+} &= 
  \begin{cases}
    \infty & \mu[f > 0] > 1 \\
    0 & \mu[f > 0] < 1 \\
    \exp \int_{f > 0} \log f\,d\mu & \mu[f > 0] = 1 \\
  \end{cases}
  \]
  provided $\norm{f}_q < \infty$ for some $q \in (0, \infty)$.
  Similarly
  \[
  \norm{f}_{0^-} &=
  \begin{cases}
    0 & \mu[f < \infty] > 1 \\
    \infty & \mu[f < \infty] < 1 \\
    \exp \int_{f < \infty} \log f\,d\mu & \mu[f < \infty] = 1 \\    
  \end{cases}
  \]
  provided $\norm{f}_q > 0$ for some $q \in (-\infty, 0)$.
\end{theorem}
\begin{proof}
  It suffices by symmetry to consider only $\norm{f}_{0^+}$.

  The provision implies $f < \infty$ almost everywhere.
  For the first two cases, we decompose $f$ into monotone parts $f^p[0 < f \le 1] + f^p[f > 1]$ as in \cref{thm:limit positive}
  to show $\lim_{p \to 0^+} \int f^p\,d\mu = \mu[f > 0]$, which implies the result.

  For the last case, we observe that $\frac{x^p - 1}{p} \searrow \ln x$ as $p \to 0^+$ for $x \in [0, \infty]$;
  this follows from convexity of $p \mapsto x^p$ and L'H\^opital's rule.
  We know by \cref{thm:power mean} applied to the probability space $[f > 0]$ that the limit exists.
  Thus for one direction we can show the inequality:
  \[
  \lim_{p \to 0^+} \ln \norm{f}_p &\le \lim_{p \to 0^+} \frac{\norm{f}_p^p - 1}{p} \\
  &= \lim_{p \to 0^+} \int_{f > 0} \frac{f^p - 1}{p}\,d\mu &\mu[f > 0] = 1 \\
  &= \int_{f > 0} \lim_{p \to 0^+} \frac{f^p - 1}{p}\,d\mu &\text{monotone convergence} \\
  &= \int_{f > 0} \ln f\,d\mu \\
  \lim_{p \to 0^+} \norm{f}_p &\le \exp \int_{f > 0} \log f\,d\mu \\
  \]
  where monotone convergence again applies because $\norm{f}_q < \infty$.
  On the other hand we can apply Jensen's inequality to find
  \[
  \exp \int_{f > 0} \log f\,d\mu 
  &= \exp \frac1p \int_{f > 0} \log f^p \,d\mu \\
  &\le \exp \frac1p \log \int_{f > 0} f^p \,d\mu \\
  &= \norm{f}_p
  \]
  for every $p > 0$,
  which completes the proof.
\end{proof}

In particular, \cref{thm:limit zero} means $\norm{f}_{0^+}$ and $\norm{f}_{0^-}$ always exist.

\begin{corollary}\label{cor:limit zero prob}
  If $\mu(S) = 1$, then $\norm{f}_{0^+} = \exp \int \log f\,d\mu$ provided $\norm{f}_q < \infty$ for some $q > 0$;
  similarly $\norm{f}_{0^-} = \exp \int \log f\,d\mu$ provided $\norm{f}_q > 0$ for some $q < 0$.
\end{corollary}
\begin{proof}
  If $\mu[f > 0] = 1$ then we have $\norm{f}_{0^+} = \exp \int_{f > 0} \log f\,d\mu = \exp \int \log f\,d\mu$.
  On the other hand, if $\mu[f > 0] < 1$ then we have $\norm{f}_{0^+} = 0 = \exp(-\infty) = \exp \int \log f\,d\mu$.
\end{proof}

\section*{More Inequalities}

\begin{theorem}[H\"older's Inequality]
  Let $f_1, \dots, f_n : S \to [0, \infty]$ be measurable functions
  and let $p_1, \dots, p_n, r \in (0, \infty]$ such that $\sum_i \frac1{p_i} = \frac1r$.
  Then
  \[\norm*{\prod_i f_i}_r \le \prod_i \norm{f_i}_{p_i}\]
\end{theorem}
\begin{proof}
  Without loss of generality assume none of the $p_i$ or $r$ is $\infty$, and all $\norm{f_i}_{p_i} \in (0, \infty)$ (since if $\norm{f_i}_{p_i} = 0$ then $f_i = 0$ a.e.).
  We can further assume $r = 1$ by applying $f_i \mapsto f_i^r$, $p_i \mapsto \frac{r}{p_i}$.

  By \cref{thm:power mean,cor:limit zero prob}
  applied to the discrete probability space $\left(\frac{1}{p_1}, \dots, \frac{1}{p_n}\right)$
  we have for any $a_i \in [0, \infty]$:
  \[
  \sum_i \frac{1}{p_i} a_i^{p_i}
  &\ge \exp \sum_i \frac{1}{p_i} \log a_i^{p_i} \\
  &= \prod_i a_i
  \]
  Letting $a_i = \frac{f_i}{\norm{f_i}_{p_i}}$ and integrating we find
  \[
  \int \prod_i \frac{f_i}{\norm{f_i}_{p_i}}\,d\mu
  &\le \int \sum_i \frac{1}{p_i} \left(\frac{f_i}{\norm{f_i}_{p_i}}\right)^{p_i}\,d\mu \\
  &= \sum_i \frac1{p_i} \cdot \frac{\int f_i^{p_i}\,d\mu}{\norm{f_i}_{p_i}^{p_i}} \\
  &= \sum_i \frac1{p_i} = 1 \\
  \int \prod_i f_i\,d\mu &\le \prod_i \norm{f_i}_{p_i} \\
  \]
\end{proof}

\begin{theorem}[Minkowski's Inequality]
  todo
\end{theorem}

\begin{theorem}[lp inequality for $\mu f in s > c$]
  (xxx check conditions)
  If $S$ is $\N$ with the counting measure and $p \le q$ then $\norm{f}_p \ge \norm{f}_q$.
\end{theorem}
\begin{proof}
  Without loss of generality assume $\norm{f}_p = 1$.
  Then each $f(i) \le 1$, etc
\end{proof}

\end{document}
